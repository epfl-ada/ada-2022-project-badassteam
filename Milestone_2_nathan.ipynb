{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fffe6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from lxml import objectify\n",
    "%matplotlib inline\n",
    "\n",
    "# Analysis of the lexical fields\n",
    "from empath import Empath \n",
    "\n",
    "data_folder = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b1e12",
   "metadata": {},
   "source": [
    "### Import of movie metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07be8e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_date</th>\n",
       "      <th>Movie_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>/m/0crgdbh</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>{\"/m/05f_3\": \"Norwegian Language\"}</td>\n",
       "      <td>{\"/m/05b4w\": \"Norway\"}</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363483</td>\n",
       "      <td>/m/0285_cd</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/07ssc\": \"United Kingdom\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261236</td>\n",
       "      <td>/m/01mrr1</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/04306rv\": \"German Language\"}</td>\n",
       "      <td>{\"/m/0345h\": \"Germany\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81736</th>\n",
       "      <td>35228177</td>\n",
       "      <td>/m/0j7hxnt</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>2011-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81737</th>\n",
       "      <td>34980460</td>\n",
       "      <td>/m/0g4pl34</td>\n",
       "      <td>Knuckle</td>\n",
       "      <td>2011-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/03rt9\": \"Ireland\", \"/m/07ssc\": \"United Ki...</td>\n",
       "      <td>{\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81738</th>\n",
       "      <td>9971909</td>\n",
       "      <td>/m/02pygw1</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>1972-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81739</th>\n",
       "      <td>913762</td>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>{\"/m/03_9r\": \"Japanese Language\"}</td>\n",
       "      <td>{\"/m/03_3d\": \"Japan\"}</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81740</th>\n",
       "      <td>12476867</td>\n",
       "      <td>/m/02w7zz8</td>\n",
       "      <td>Spliced</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/0d060g\": \"Canada\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81741 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia_movie_ID Freebase_movie_ID  \\\n",
       "0                  975900         /m/03vyhn   \n",
       "1                 3196793         /m/08yl5d   \n",
       "2                28463795        /m/0crgdbh   \n",
       "3                 9363483        /m/0285_cd   \n",
       "4                  261236         /m/01mrr1   \n",
       "...                   ...               ...   \n",
       "81736            35228177        /m/0j7hxnt   \n",
       "81737            34980460        /m/0g4pl34   \n",
       "81738             9971909        /m/02pygw1   \n",
       "81739              913762         /m/03pcrp   \n",
       "81740            12476867        /m/02w7zz8   \n",
       "\n",
       "                                              Movie_name  Movie_date  \\\n",
       "0                                         Ghosts of Mars  2001-08-24   \n",
       "1      Getting Away with Murder: The JonBenét Ramsey ...  2000-02-16   \n",
       "2                                            Brun bitter        1988   \n",
       "3                                       White Of The Eye        1987   \n",
       "4                                      A Woman in Flames        1983   \n",
       "...                                                  ...         ...   \n",
       "81736                           Mermaids: The Body Found  2011-03-19   \n",
       "81737                                            Knuckle  2011-01-21   \n",
       "81738                                  Another Nice Mess  1972-09-22   \n",
       "81739  The Super Dimension Fortress Macross II: Lover...  1992-05-21   \n",
       "81740                                            Spliced        2002   \n",
       "\n",
       "       Movie_revenue  Movie_runtime                     Movie_languages  \\\n",
       "0         14010832.0           98.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "1                NaN           95.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "2                NaN           83.0  {\"/m/05f_3\": \"Norwegian Language\"}   \n",
       "3                NaN          110.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "4                NaN          106.0   {\"/m/04306rv\": \"German Language\"}   \n",
       "...              ...            ...                                 ...   \n",
       "81736            NaN          120.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "81737            NaN           96.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "81738            NaN           66.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "81739            NaN          150.0   {\"/m/03_9r\": \"Japanese Language\"}   \n",
       "81740            NaN           86.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "                                         Movie_countries  \\\n",
       "0              {\"/m/09c7w0\": \"United States of America\"}   \n",
       "1              {\"/m/09c7w0\": \"United States of America\"}   \n",
       "2                                 {\"/m/05b4w\": \"Norway\"}   \n",
       "3                         {\"/m/07ssc\": \"United Kingdom\"}   \n",
       "4                                {\"/m/0345h\": \"Germany\"}   \n",
       "...                                                  ...   \n",
       "81736          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "81737  {\"/m/03rt9\": \"Ireland\", \"/m/07ssc\": \"United Ki...   \n",
       "81738          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "81739                              {\"/m/03_3d\": \"Japan\"}   \n",
       "81740                            {\"/m/0d060g\": \"Canada\"}   \n",
       "\n",
       "                                            Movie_genres  \n",
       "0      {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n",
       "1      {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  \n",
       "2      {\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...  \n",
       "3      {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...  \n",
       "4                                {\"/m/07s9rl0\": \"Drama\"}  \n",
       "...                                                  ...  \n",
       "81736                            {\"/m/07s9rl0\": \"Drama\"}  \n",
       "81737  {\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...  \n",
       "81738       {\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}  \n",
       "81739  {\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...  \n",
       "81740  {\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...  \n",
       "\n",
       "[81741 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Movie metadata import\n",
    "df_movie = pd.read_table(data_folder +'movie.metadata.tsv',header=None)\n",
    "df_movie.columns=['Wikipedia_movie_ID' , 'Freebase_movie_ID', 'Movie_name' , 'Movie_date' , 'Movie_revenue' , 'Movie_runtime' , 'Movie_languages' , 'Movie_countries' , 'Movie_genres']\n",
    "df_movie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ab762",
   "metadata": {},
   "source": [
    "### Country of origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e41f17",
   "metadata": {},
   "source": [
    "There are often several countries for each movie. Thus, we consider that a movie is american when the USA belongs to the countries of origin of a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b2d2909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of american movies: 34408\n",
      "Number of british movies: 7868\n",
      "Number of french movies: 4395\n",
      "Number of indian movies: 8411\n",
      "Number of chinese movies: 645\n"
     ]
    }
   ],
   "source": [
    "df_movie = pd.read_table(data_folder +'movie.metadata.tsv',header=None)\n",
    "df_movie.columns=['Wikipedia_movie_ID' , 'Freebase_movie_ID', 'Movie_name' , 'Movie_date' , 'Movie_revenue' , 'Movie_runtime' , 'Movie_languages' , 'Movie_countries' , 'Movie_genres']\n",
    "df_movie['Movie_countries'] = df_movie['Movie_countries'].apply( lambda x: list(eval(x).keys()))\n",
    "df_movie['Movie_genres'] = df_movie['Movie_genres'].apply( lambda x: list(eval(x).values()) )\n",
    "countries = df_movie['Movie_countries'].explode().value_counts()\n",
    "\n",
    "\n",
    "print('Number of american movies: '+str(countries['/m/09c7w0']))\n",
    "print('Number of british movies: '+str(countries['/m/07ssc']))\n",
    "print('Number of french movies: '+str(countries['/m/0f8l9c']))\n",
    "print('Number of indian movies: '+str(countries['/m/03rk0']))\n",
    "print('Number of chinese movies: '+str(countries['/m/0d05w3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbf493d",
   "metadata": {},
   "source": [
    "### Selecting american movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0489cdfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_date</th>\n",
       "      <th>Movie_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>[/m/09c7w0]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>[/m/09c7w0]</td>\n",
       "      <td>[Mystery, Biographical film, Drama, Crime Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13696889</td>\n",
       "      <td>/m/03cfc81</td>\n",
       "      <td>The Gangsters</td>\n",
       "      <td>1913-05-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>{\"/m/06ppq\": \"Silent film\", \"/m/02h40lc\": \"Eng...</td>\n",
       "      <td>[/m/09c7w0]</td>\n",
       "      <td>[Short Film, Silent film, Indie, Black-and-whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10408933</td>\n",
       "      <td>/m/02qc0j7</td>\n",
       "      <td>Alexander's Ragtime Band</td>\n",
       "      <td>1938-08-16</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>[/m/09c7w0]</td>\n",
       "      <td>[Musical, Comedy, Black-and-white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175026</td>\n",
       "      <td>/m/017n1p</td>\n",
       "      <td>Sarah and Son</td>\n",
       "      <td>1930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>[/m/09c7w0]</td>\n",
       "      <td>[Drama, Black-and-white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81725</th>\n",
       "      <td>1918494</td>\n",
       "      <td>/m/0660qx</td>\n",
       "      <td>State and Main</td>\n",
       "      <td>2000-08-26</td>\n",
       "      <td>6944471.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/02bjrlw\": \"Italian Language\", \"/m/02h40lc...</td>\n",
       "      <td>[/m/0f8l9c, /m/09c7w0]</td>\n",
       "      <td>[Parody, Americana, Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81726</th>\n",
       "      <td>664006</td>\n",
       "      <td>/m/030xw6</td>\n",
       "      <td>Guilty as Sin</td>\n",
       "      <td>1993-06-04</td>\n",
       "      <td>22886222.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>[/m/09c7w0]</td>\n",
       "      <td>[Thriller, Erotic thriller, Psychological thri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81727</th>\n",
       "      <td>24209227</td>\n",
       "      <td>/m/07k5mlk</td>\n",
       "      <td>The Time, the Place and the Girl</td>\n",
       "      <td>1946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>[/m/09c7w0]</td>\n",
       "      <td>[Comedy film, Romance Film, Musical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81736</th>\n",
       "      <td>35228177</td>\n",
       "      <td>/m/0j7hxnt</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>2011-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>[/m/09c7w0]</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81738</th>\n",
       "      <td>9971909</td>\n",
       "      <td>/m/02pygw1</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>1972-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>[/m/09c7w0]</td>\n",
       "      <td>[Satire, Comedy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34408 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia_movie_ID Freebase_movie_ID  \\\n",
       "0                  975900         /m/03vyhn   \n",
       "1                 3196793         /m/08yl5d   \n",
       "5                13696889        /m/03cfc81   \n",
       "7                10408933        /m/02qc0j7   \n",
       "10                 175026         /m/017n1p   \n",
       "...                   ...               ...   \n",
       "81725             1918494         /m/0660qx   \n",
       "81726              664006         /m/030xw6   \n",
       "81727            24209227        /m/07k5mlk   \n",
       "81736            35228177        /m/0j7hxnt   \n",
       "81738             9971909        /m/02pygw1   \n",
       "\n",
       "                                              Movie_name  Movie_date  \\\n",
       "0                                         Ghosts of Mars  2001-08-24   \n",
       "1      Getting Away with Murder: The JonBenét Ramsey ...  2000-02-16   \n",
       "5                                          The Gangsters  1913-05-29   \n",
       "7                               Alexander's Ragtime Band  1938-08-16   \n",
       "10                                         Sarah and Son        1930   \n",
       "...                                                  ...         ...   \n",
       "81725                                     State and Main  2000-08-26   \n",
       "81726                                      Guilty as Sin  1993-06-04   \n",
       "81727                   The Time, the Place and the Girl        1946   \n",
       "81736                           Mermaids: The Body Found  2011-03-19   \n",
       "81738                                  Another Nice Mess  1972-09-22   \n",
       "\n",
       "       Movie_revenue  Movie_runtime  \\\n",
       "0         14010832.0           98.0   \n",
       "1                NaN           95.0   \n",
       "5                NaN           35.0   \n",
       "7          3600000.0          106.0   \n",
       "10               NaN           86.0   \n",
       "...              ...            ...   \n",
       "81725      6944471.0          106.0   \n",
       "81726     22886222.0          107.0   \n",
       "81727            NaN          105.0   \n",
       "81736            NaN          120.0   \n",
       "81738            NaN           66.0   \n",
       "\n",
       "                                         Movie_languages  \\\n",
       "0                     {\"/m/02h40lc\": \"English Language\"}   \n",
       "1                     {\"/m/02h40lc\": \"English Language\"}   \n",
       "5      {\"/m/06ppq\": \"Silent film\", \"/m/02h40lc\": \"Eng...   \n",
       "7                     {\"/m/02h40lc\": \"English Language\"}   \n",
       "10                    {\"/m/02h40lc\": \"English Language\"}   \n",
       "...                                                  ...   \n",
       "81725  {\"/m/02bjrlw\": \"Italian Language\", \"/m/02h40lc...   \n",
       "81726                                                 {}   \n",
       "81727                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "81736                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "81738                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "              Movie_countries  \\\n",
       "0                 [/m/09c7w0]   \n",
       "1                 [/m/09c7w0]   \n",
       "5                 [/m/09c7w0]   \n",
       "7                 [/m/09c7w0]   \n",
       "10                [/m/09c7w0]   \n",
       "...                       ...   \n",
       "81725  [/m/0f8l9c, /m/09c7w0]   \n",
       "81726             [/m/09c7w0]   \n",
       "81727             [/m/09c7w0]   \n",
       "81736             [/m/09c7w0]   \n",
       "81738             [/m/09c7w0]   \n",
       "\n",
       "                                            Movie_genres  \n",
       "0      [Thriller, Science Fiction, Horror, Adventure,...  \n",
       "1       [Mystery, Biographical film, Drama, Crime Drama]  \n",
       "5      [Short Film, Silent film, Indie, Black-and-whi...  \n",
       "7                     [Musical, Comedy, Black-and-white]  \n",
       "10                              [Drama, Black-and-white]  \n",
       "...                                                  ...  \n",
       "81725                        [Parody, Americana, Comedy]  \n",
       "81726  [Thriller, Erotic thriller, Psychological thri...  \n",
       "81727               [Comedy film, Romance Film, Musical]  \n",
       "81736                                            [Drama]  \n",
       "81738                                   [Satire, Comedy]  \n",
       "\n",
       "[34408 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usa = df_movie.loc[df_movie['Movie_countries'].explode().isin(['/m/09c7w0'])[df_movie['Movie_countries'].explode().isin(['/m/09c7w0'])].index]\n",
    "\n",
    "df_usa\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e1f7a7",
   "metadata": {},
   "source": [
    "### Import character metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0578fe89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bette Davis          96\n",
       "Mae Questel          95\n",
       "Charlotte Burton     84\n",
       "Joan Crawford        81\n",
       "Claudette Colbert    79\n",
       "Susan Sarandon       77\n",
       "Cloris Leachman      75\n",
       "Barbara Stanwyck     75\n",
       "Myrna Loy            75\n",
       "Blanche Sweet        74\n",
       "Lillian Gish         71\n",
       "Whoopi Goldberg      67\n",
       "Kathy Bates          65\n",
       "Vivian Rich          65\n",
       "Mabel Normand        62\n",
       "Joan Blondell        61\n",
       "Lucille Ball         61\n",
       "Daryl Hannah         61\n",
       "Shelley Winters      59\n",
       "Ginger Rogers        59\n",
       "Mary Steenburgen     59\n",
       "Mary Pickford        57\n",
       "Karen Black          57\n",
       "Gloria Swanson       57\n",
       "Julianne Moore       56\n",
       "Angela Lansbury      55\n",
       "Loretta Young        55\n",
       "Louise Lester        55\n",
       "June Foray           55\n",
       "Ellen Burstyn        54\n",
       "Name: Actor_name, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Character metadata\n",
    "df_character = pd.read_table(data_folder +'character.metadata.tsv',header=None)\n",
    "df_character.columns=['Wikipedia_movie_ID' , 'Freebase_movie_ID' , 'Movie_date' , 'Character_name' , 'Actor_date_of_birth' , 'Actor_gender' , 'Actor_height' , 'Actor_ethnicity' , 'Actor_name' , 'Actor_age_at_movie_release' , 'Freebase_character_actor_ID' , 'Freebase_character_ID' , 'Freebase_actor_ID'  ]\n",
    "\n",
    "#Correct negative or too high actor age\n",
    "df_character['Actor_age_at_movie_release']=df_character['Actor_age_at_movie_release'].apply(lambda x: -x if x<0 else x)\n",
    "df_character['Actor_age_at_movie_release']=df_character['Actor_age_at_movie_release'].apply(lambda x: float(\"nan\") if x>130 else x)\n",
    "\n",
    "\n",
    "\n",
    "#Character of american movies\n",
    "df_character_usa = df_character.merge(df_usa['Freebase_movie_ID'], on='Freebase_movie_ID')\n",
    "\n",
    "#Number of american actor/actress citation\n",
    "df_character_usa[df_character_usa['Actor_gender']=='F']['Actor_name'].value_counts().head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9df2c3",
   "metadata": {},
   "source": [
    "### Revenue VS Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6e4173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_revenue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Plot of revenue vs runtime\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(data\u001b[38;5;241m=\u001b[39m\u001b[43mdf_revenue\u001b[49m[(df_revenue\u001b[38;5;241m.\u001b[39mMovie_runtime\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m400\u001b[39m) \u001b[38;5;241m&\u001b[39m (df_revenue\u001b[38;5;241m.\u001b[39mMovie_revenue\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m1500000000\u001b[39m) ] , x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMovie_runtime\u001b[39m\u001b[38;5;124m'\u001b[39m , y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMovie_revenue\u001b[39m\u001b[38;5;124m'\u001b[39m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_revenue' is not defined"
     ]
    }
   ],
   "source": [
    "#Plot of revenue vs runtime\n",
    "sns.scatterplot(data=df_revenue[(df_revenue.Movie_runtime<400) & (df_revenue.Movie_revenue<1500000000) ] , x='Movie_runtime' , y='Movie_revenue' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cf6fc2",
   "metadata": {},
   "source": [
    "### Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genre_count = df_usa['Movie_genres'].explode().value_counts()\n",
    "\n",
    "#Dataframe with each rows corresponding to a genre\n",
    "\n",
    "#Definition of the minimal number of movies per genre\n",
    "min_genre = 1000\n",
    "\n",
    "#Initialisation of the dictionnary\n",
    "dic_genre_describe = dict.fromkeys(genre_count[genre_count > min_genre].index, [])\n",
    "dic_usa_genre = dict.fromkeys(genre_count[genre_count > min_genre].index, [])\n",
    "\n",
    "#Filling of the dictionnary\n",
    "for ctr,genre in enumerate(dic_genre.keys()):\n",
    "    #Movie metadata dataframe for each genre\n",
    "    df_movie_temp = df_usa.loc[df_usa['Movie_genres'].explode()[df_usa['Movie_genres'].explode() == genre].index] \n",
    "    #Character metadata dataframe for each genre\n",
    "    df_character_temp = df_character.merge(df_movie_temp['Freebase_movie_ID'], on='Freebase_movie_ID') #merge character and movie metadata dataframe\n",
    "\n",
    "    \n",
    "    #Adding character info into movie_metadata\n",
    "    df_temp=pd.DataFrame()\n",
    "    df_temp=pd.concat( [df_character_temp[df_character_temp.Actor_gender=='F'].groupby('Freebase_movie_ID').agg('count')['Actor_gender'],\n",
    "                        df_character_temp[df_character_temp.Actor_gender=='F'].groupby('Freebase_movie_ID').agg('mean')['Actor_age_at_movie_release'],\n",
    "                        df_character_temp[df_character_temp.Actor_gender=='M'].groupby('Freebase_movie_ID').agg('count')['Actor_gender'],\n",
    "                        df_character_temp[df_character_temp.Actor_gender=='M'].groupby('Freebase_movie_ID').agg('mean')['Actor_age_at_movie_release'] ],axis=1)\n",
    "    df_temp.columns=[\"Number_of_women\",\"Mean_women_age\",\"Number_of_men\",\"Mean_men_age\"]\n",
    "    df_movie_temp = df_movie_temp.merge(df_temp, on='Freebase_movie_ID') #merge to add character info to movie info\n",
    "    df_movie_temp['Women_percentage'] = (df_movie_temp['Number_of_women']/(df_movie_temp['Number_of_men']+df_movie_temp['Number_of_women']))*100\n",
    "    \n",
    "    #Dataframe for each genre are stored in a dictionnary\n",
    "    dic_usa_genre[genre]={'movie_metadata':df_movie_temp,'character_metadata':df_character_temp}\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Description features for each genre\n",
    "    dic_genre_describe[genre] = {'Number_of_movies': len(df_movie_temp),\n",
    "                        'Mean_age_f' : df_character_temp[df_character_temp.Actor_gender == 'F']['Actor_age_at_movie_release'].mean() ,\n",
    "                        'Std_age_f' : df_character_temp[df_character_temp.Actor_gender == 'F']['Actor_age_at_movie_release'].std() ,\n",
    "                        'Median_age_f' : df_character_temp[df_character_temp.Actor_gender == 'F']['Actor_age_at_movie_release'].median() ,\n",
    "                        'Mean_number_f' : df_character_temp[ df_character_temp.Actor_gender == 'F'].groupby('Freebase_movie_ID')['Actor_gender'].agg('count').mean() ,\n",
    "                        'Mean_age_m' : df_character_temp[df_character_temp.Actor_gender == 'M']['Actor_age_at_movie_release'].mean() ,\n",
    "                        'Std_age_m' : df_character_temp[df_character_temp.Actor_gender == 'M']['Actor_age_at_movie_release'].std() ,\n",
    "                        'Median_age_m' : df_character_temp[df_character_temp.Actor_gender == 'M']['Actor_age_at_movie_release'].median(),\n",
    "                        'Mean_number_m': df_character_temp[ df_character_temp.Actor_gender == 'M'].groupby('Freebase_movie_ID')['Actor_gender'].agg('count').mean(),\n",
    "                        'Mean_revenue': df_movie_temp['Movie_revenue'].mean()\n",
    "                       }\n",
    "    \n",
    "df_usa_genre_describe = pd.DataFrame.from_dict(dic_genre_describe , orient='index')\n",
    "df_usa_genre_describe['Women_percentage']= (df_usa_genre_describe['Mean_number_f']/(df_usa_genre_describe['Mean_number_m']+df_usa_genre_describe['Mean_number_f']))*100\n",
    "df_usa_genre_describe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f382975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_usa_genre_describe.copy()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "ax = sns.barplot(x=df['Number_of_movies'].index, y=df['Number_of_movies'].values, alpha=0.8)\n",
    "ax.set_xlabel('Movie genre')\n",
    "ax.set_ylabel('Number of occurrences')\n",
    "ax.set_xticklabels(df['Number_of_movies'].index, rotation='vertical', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9701ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_usa_genre_describe.copy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.figsize=(8,4)\n",
    "sns.barplot(x=df['Mean_age_f'].index, y=df['Mean_age_f'].values, alpha=0.8, ax=ax[0])\n",
    "sns.barplot(x=df['Mean_age_m'].index, y=df['Mean_age_m'].values, alpha=0.8, ax=ax[1])\n",
    "ax[0].set_xlabel('Movie genre')\n",
    "ax[1].set_xlabel('Movie genre')\n",
    "ax[0].set_ylabel('Mean women age ')\n",
    "ax[1].set_ylabel('Mean men age')\n",
    "ax[0].set_xticklabels(df['Mean_age_f'].index, rotation='vertical', fontsize=10)\n",
    "ax[1].set_xticklabels(df['Mean_age_m'].index, rotation='vertical', fontsize=10)\n",
    "ax[0].set_ylim([0, 50])\n",
    "ax[1].set_ylim([0, 50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d047a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_usa_genre_describe.copy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.figsize=(8,4)\n",
    "sns.barplot(x=df['Mean_number_f'].index, y=df['Mean_number_f'].values, alpha=0.8, ax=ax[0])\n",
    "sns.barplot(x=df['Mean_number_m'].index, y=df['Mean_number_m'].values, alpha=0.8, ax=ax[1])\n",
    "ax[0].set_xlabel('Movie genre')\n",
    "ax[1].set_xlabel('Movie genre')\n",
    "ax[0].set_ylabel('Mean number of women ')\n",
    "ax[1].set_ylabel('Mean number of men')\n",
    "ax[0].set_xticklabels(df['Mean_number_f'].index, rotation='vertical', fontsize=10)\n",
    "ax[1].set_xticklabels(df['Mean_number_m'].index, rotation='vertical', fontsize=10)\n",
    "ax[0].set_ylim([0, 9])\n",
    "ax[1].set_ylim([0, 9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faac9848",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71065ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dic_usa_genre[genre]['movie_metadata']\n",
    "sns.boxplot(data=df[df['Movie_date']<'1960'],y='Mean_women_age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df[df['Movie_date']>'1960'],y='Mean_women_age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423debba",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=df_usa_genre.copy()\n",
    "\n",
    "\n",
    "#Standardize continuous variable\n",
    "df['Women_percentage'] = (df['Women_percentage'] - df['Women_percentage'].mean())/df['Women_percentage'].std()\n",
    "df['Mean_age_f'] = (df['Mean_age_f'] - df['Mean_age_f'].mean())/df['Mean_age_f'].std()\n",
    "df['Mean_age_m'] = (df['Mean_age_m'] - df['Mean_age_m'].mean())/df['Mean_age_m'].std()\n",
    "df['Mean_revenue'] = (df['Mean_revenue'] - df['Mean_revenue'].mean())/df['Mean_revenue'].std()\n",
    "\n",
    "\n",
    "\n",
    "# Declares the model\n",
    "mod = smf.ols(formula='Women_percentage ~ (Mean_age_f) + (Mean_age_m) + (Mean_revenue)', data=df)\n",
    "\n",
    "# Fits the model (find the optimal coefficients, adding a random seed ensures consistency)\n",
    "\n",
    "res = mod.fit()\n",
    "\n",
    "# Print thes summary output provided by the library.\n",
    "print(res.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d9ee10",
   "metadata": {},
   "source": [
    "### Selecting movies only when we know the revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f374eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting a dataframe\n",
    "df=df_usa\n",
    "df_revenue_usa=df.dropna(subset=['Movie_revenue'])\n",
    "\n",
    "\n",
    "print('Percentage of known american movies revenue:'+str(len(df_revenue_usa)/len(df_usa)*100)+' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See the distribution of movie revenues\n",
    "sns.histplot(data=df_revenue_usa, x='Movie_revenue', stat = 'count' , log_scale= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d287b3",
   "metadata": {},
   "source": [
    "### 50 more expensive movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ebc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the 50 more expensive movies\n",
    "df_revenue.sort_values(by='Movie_revenue' , axis=0 , ascending = False)\n",
    "df_most_expensive_movies = df_revenue.sort_values(by='Movie_revenue' , axis=0 , ascending = False).iloc[0:50]\n",
    "df_most_expensive_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd17af",
   "metadata": {},
   "source": [
    "### Principal characters: male or female?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c295e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_most_expensive_movies.copy()\n",
    "\n",
    "principal_character = []\n",
    "for ctr,movie in enumerate(list(df['Wikipedia_movie_ID'].values)) :\n",
    "    \n",
    "    path = data_folder+'/corenlp_plot_summaries/'+str(movie)+'.xml'\n",
    "    if os.path.exists(path):\n",
    "        #Extract dataframe from xml file\n",
    "        df_summary=pd.DataFrame()\n",
    "        df_summary = pd.read_xml(data_folder+'/corenlp_plot_summaries/'+str(movie)+'.xml' , xpath='//token',parser='lxml')\n",
    "        df_summary.rename(columns={'id':'word_id'},inplace=True)\n",
    "        df_summary.insert(0, \"sentence_id\",df_summary['word_id'].ne(df_summary['word_id'].shift()+1).cumsum(), True) #add sentence id by indexing sequences \n",
    "        df_summary = df_summary[df_summary['NER'] == 'PERSON']\n",
    "        principal_character.append( df_summary['word'].value_counts().index[0] )\n",
    "        \n",
    "df['Principal_character']=principal_character\n",
    "df       \n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1725590",
   "metadata": {},
   "source": [
    "### Lexical fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ctr,genre in enumerate(dic_genre):\n",
    "df=df_most_expensive_movies\n",
    "\n",
    "#Initialization\n",
    "lexicon = Empath()\n",
    "df_lex_fields = pd.DataFrame()\n",
    "dic_lex_fields=dict.fromkeys(df['Wikipedia_movie_ID'].values,[])\n",
    "\n",
    "for ctr,movie in enumerate(list(df['Wikipedia_movie_ID'].values)) :\n",
    "\n",
    "    path = data_folder+'/corenlp_plot_summaries/'+str(movie)+'.xml'\n",
    "    if os.path.exists(path):\n",
    "        #Extract dataframe from xml file\n",
    "        df_summary=pd.DataFrame()\n",
    "        df_summary = pd.read_xml(data_folder+'/corenlp_plot_summaries/'+str(movie)+'.xml' , xpath='//token',parser='lxml')\n",
    "        df_summary.rename(columns={'id':'word_id'},inplace=True)\n",
    "        df_summary.insert(0, \"sentence_id\",df_summary['word_id'].ne(df_summary['word_id'].shift()+1).cumsum(), True) #add sentence id by indexing sequences  \n",
    "\n",
    "\n",
    "        features_lex_fields = pd.Series([lexicon.analyze(list(df_summary['word'].values), categories = [\"feminine\",\"sexist\",\"sexiest\",\"beauty\",\"beautiful\",\"positive_emotion\",\"negative_emotion\"])])\n",
    "\n",
    "        dic_lex_fields[movie]= features_lex_fields[0]\n",
    "        dic_lex_fields[movie]['Number_of_words']=len(df_summary)\n",
    "\n",
    "\n",
    "\n",
    "df_lex_fields = pd.DataFrame.from_dict(dic_lex_fields, orient='index')  \n",
    "df_lex_fields.insert(loc=0, column='Movie_name', value=df['Movie_name'].values)\n",
    "df_lex_fields.insert(loc=1, column='Freebase_movie_ID', value=df['Freebase_movie_ID'].values)\n",
    "df_most_expensive_movies_summary=df_most_expensive_movies.merge(df_lex_fields, on='Freebase_movie_ID')\n",
    "df_most_expensive_movies_summary\n",
    "\n",
    "\n",
    "#df_lex_fields[['Movie_name','Freebase_movie_ID','sexual']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d24562e",
   "metadata": {},
   "source": [
    "### Number of occurence of lexical field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de3902",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature='feminine'\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "ax = sns.barplot(x=df_lex_fields['Movie_name'], y=df_lex_fields[feature].values, alpha=0.8)\n",
    "ax.set_xlabel('Movie name')\n",
    "ax.set_ylabel('Number of occurrences of '+feature+' related words')\n",
    "ax.set_xticklabels(df_lex_fields['Movie_name'], rotation='vertical', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81094a",
   "metadata": {},
   "source": [
    "### Positive VS negative emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf133fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1='positive_emotion'\n",
    "feature2='negative_emotion'\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.figsize=(8,4)\n",
    "sns.barplot(x=df_lex_fields['Movie_name'], y=df_lex_fields[feature1].values, alpha=0.8, ax=ax[0])\n",
    "sns.barplot(x=df_lex_fields['Movie_name'], y=df_lex_fields[feature2].values, alpha=0.8, ax=ax[1])\n",
    "ax[0].set_xlabel('Movie name')\n",
    "ax[1].set_xlabel('Movie name')\n",
    "ax[0].set_ylabel('Number of occurrences of '+feature1+' related words')\n",
    "ax[1].set_ylabel('Number of occurrences of '+feature2+' related words')\n",
    "ax[0].set_xticklabels(df_lex_fields['Movie_name'], rotation='vertical', fontsize=10)\n",
    "ax[1].set_xticklabels(df_lex_fields['Movie_name'], rotation='vertical', fontsize=10)\n",
    "ax[0].set_ylim([0, 18])\n",
    "ax[1].set_ylim([0, 18])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8503f1e",
   "metadata": {},
   "source": [
    "### Ratio of he/she used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd80106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "he_count,she_count=[],[]\n",
    "for ctr,movie in enumerate(list(df_most_expensive_movies['Wikipedia_movie_ID'].values)) :\n",
    "    \n",
    "    path = data_folder+'/corenlp_plot_summaries/'+str(movie)+'.xml'\n",
    "    if os.path.exists(path):\n",
    "        #Extract dataframe from xml file\n",
    "        df_summary=pd.DataFrame()\n",
    "        df_summary = pd.read_xml(data_folder+'/corenlp_plot_summaries/'+str(movie)+'.xml' , xpath='//token',parser='lxml')\n",
    "        df_summary.rename(columns={'id':'word_id'},inplace=True)\n",
    "        df_summary.insert(0, \"sentence_id\",df_summary['word_id'].ne(df_summary['word_id'].shift()+1).cumsum(), True) #add sentence id by indexing sequences  \n",
    "\n",
    "        #Filter only the pronouns\n",
    "        df_summary_pronouns= df_summary[df_summary.POS=='PRP']\n",
    "        #Count the number of redundant words \n",
    "        personal_pronouns = df_summary_pronouns.groupby(['word'])['word'].count().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "        if 'he' in list(personal_pronouns.index):\n",
    "            he_count.append( personal_pronouns['he'])\n",
    "        else:\n",
    "            he_count.append( 0 )\n",
    "\n",
    "        if 'she' in list(personal_pronouns.index):\n",
    "            she_count.append( personal_pronouns['she'] )\n",
    "        else:\n",
    "            she_count.append(0)\n",
    "    else:\n",
    "        he_count.append(float(\"nan\"))\n",
    "        she_count.append(float(\"nan\"))\n",
    "        \n",
    "df_most_expensive_movies['he_count'] = he_count\n",
    "df_most_expensive_movies['she_count'] = she_count\n",
    "df_most_expensive_movies\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f508448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean of she and he\n",
    "df_most_expensive_movies['she_count'].mean()/df_most_expensive_movies['he_count'].mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd115b",
   "metadata": {},
   "source": [
    "### Adjective associated to a character (is beautiful adjectives associated to female character?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beautiful woman ajectives\n",
    "beautiful_woman_words = pd.read_csv(data_folder + 'beautiful_woman.txt',encoding='utf-16',names=['words'])['words'].tolist()\n",
    "\n",
    "#Choose a df\n",
    "df=df_summaries[29]\n",
    "\n",
    "#Show the character names\n",
    "if len(df)==0:\n",
    "    print('No summary available')\n",
    "else:\n",
    "    character_names = df[df['NER'] == 'PERSON']['word'].value_counts()\n",
    "    print(character_names)\n",
    "\n",
    "    #List of adjectives associated\n",
    "\n",
    "    adjectives=dict.fromkeys(character_names.index, [])\n",
    "\n",
    "    for  ctr1,character_name in enumerate(character_names.index):\n",
    "        adj=[]\n",
    "        for ctr2,sentence in enumerate(df[df.word == character_name]['sentence_id'].values): #search adjectives in each sentence in which the character is cited  \n",
    "            adj.append(df[(df.sentence_id==sentence) & ((df.POS=='JJ')| (df.POS=='NN')) ]['lemma'].values)\n",
    "        adj=[adj[i].tolist() for i in range(len(adj))]\n",
    "        adj=sum(adj, [])\n",
    "        adjectives[character_name]=bool(set(adj) & set(beautiful_woman_words))   #test if words associated to the character are beautiful woman qualifying words\n",
    "        #adjectives[character_name]=adj\n",
    " \n",
    "\n",
    "    print(adjectives)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d946b6",
   "metadata": {},
   "source": [
    "### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d874735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe with existing movie summary\n",
    "wiki_id_list = []\n",
    "for ctr,wiki_id in enumerate(list(df_usa['Wikipedia_movie_ID'])) : \n",
    "    path = data_folder+'/corenlp_plot_summaries/'+str(wiki_id)+'.xml'\n",
    "    if os.path.exists(path):\n",
    "        wiki_id_list.append(wiki_id)\n",
    "wiki_id_series = pd.Series(wiki_id_list, name='Wikipedia_movie_ID')\n",
    "\n",
    "#Data frame (movie metadata) with only existing summaries \n",
    "df_usa_summary=df_usa.merge(wiki_id_series, on='Wikipedia_movie_ID')\n",
    "df_usa_summary\n",
    "\n",
    "#Data frame (character metadata) with only existing summaries\n",
    "df_usa_character_summary=df_character_usa.merge(wiki_id_series, on='Wikipedia_movie_ID')\n",
    "df_usa_character_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae98801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary exploration\n",
    "df=df_usa_summary\n",
    "\n",
    "#Initialization\n",
    "lexicon = Empath()\n",
    "df_lex_fields = pd.DataFrame()\n",
    "dic_lex_fields=dict.fromkeys(df['Wikipedia_movie_ID'].values,[])\n",
    "\n",
    "for ctr,movie in enumerate(list(df['Wikipedia_movie_ID'].values)) :\n",
    "\n",
    "    path = data_folder+'/corenlp_plot_summaries/'+str(movie)+'.xml'\n",
    "    if os.path.exists(path):\n",
    "        #Extract dataframe from xml file and convert it into a dataframe\n",
    "        df_summary=pd.DataFrame()\n",
    "        df_summary = pd.read_xml(data_folder+'/corenlp_plot_summaries/'+str(movie)+'.xml' , xpath='//token',parser='lxml')\n",
    "        df_summary.rename(columns={'id':'word_id'},inplace=True)\n",
    "        df_summary.insert(0, \"sentence_id\",df_summary['word_id'].ne(df_summary['word_id'].shift()+1).cumsum(), True) #add sentence id by indexing sequences  \n",
    "        \n",
    "        ###Lexical field analysis\n",
    "        summary_words=list(df_summary['word'].values) #all words of the summary in a list\n",
    "        summary_words=[str(word) for word in summary_words] #convert all words to a string\n",
    "        features_lex_fields = pd.Series([lexicon.analyze(list(summary_words), categories = [\"feminine\",\"sexist\",\"sexiest\",\"beauty\",\"beautiful\",\"positive_emotion\",\"negative_emotion\"])])\n",
    "        #Store data into a dictionnary\n",
    "        dic_lex_fields[movie]= features_lex_fields[0]\n",
    "        #Add a column corresponding to the number of words in the summary\n",
    "        dic_lex_fields[movie]['Number_of_words']=len(df_summary)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###Count of he/she        \n",
    "        #Filter only the pronouns\n",
    "        df_summary_pronouns= df_summary[df_summary.POS=='PRP']\n",
    "        #Count the number of redundant words \n",
    "        personal_pronouns = df_summary_pronouns.groupby(['word'])['word'].count().sort_values(ascending=False)\n",
    "\n",
    "        if 'he' in list(personal_pronouns.index):\n",
    "            dic_lex_fields[movie]['he_count'] = personal_pronouns['he']\n",
    "        else:\n",
    "            dic_lex_fields[movie]['he_count'] = 0\n",
    "\n",
    "        if 'she' in list(personal_pronouns.index):\n",
    "            dic_lex_fields[movie]['she_count'] = personal_pronouns['she'] \n",
    "        else:\n",
    "            dic_lex_fields[movie]['she_count'] = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###Principal characters according to the summary\n",
    "        characters_name = df_summary[df_summary['NER'] == 'PERSON']['word'].value_counts().index\n",
    "        if len(characters_name)>=2:\n",
    "            dic_lex_fields[movie]['Principal_summary_character'] =  characters_name[0] \n",
    "            dic_lex_fields[movie]['Secondary_summary_character'] =  characters_name[1] \n",
    "        if len(characters_name)==1:\n",
    "            dic_lex_fields[movie]['Principal_summary_character'] =  characters_name[0] \n",
    "            dic_lex_fields[movie]['Secondary_summary_character'] =  float('nan')    \n",
    "        if len(characters_name)==0:\n",
    "            dic_lex_fields[movie]['Principal_summary_character'] =  float('nan')\n",
    "            dic_lex_fields[movie]['Secondary_summary_character'] =  float('nan')   \n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "df_lex_fields = pd.DataFrame.from_dict(dic_lex_fields, orient='index')  \n",
    "#df_lex_fields.insert(loc=0, column='Movie_name', value=df['Movie_name'].values)\n",
    "df_lex_fields.insert(loc=1, column='Freebase_movie_ID', value=df['Freebase_movie_ID'].values)\n",
    "df_usa_summary_processed=df_usa_summary.merge(df_lex_fields, on='Freebase_movie_ID')\n",
    "df_usa_summary_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_usa_summary_processed.copy()\n",
    "\n",
    "df['feminine_standardized']=df['feminine']/df['Number_of_words']\n",
    "df['beauty_standardized']=df['beauty']/df['Number_of_words']\n",
    "\n",
    "\n",
    "df_1950_2000=df[ (df['Movie_date'] < '2000') & (df['Movie_date'] > '1950') ]\n",
    "df_2000_2012=df[ (df['Movie_date'] > '2000') ]\n",
    "\n",
    "\n",
    "print('Mean of 1950-2000 over '+str(len(df_1950_2000))+' movies : '+ str(df_1950_2000['feminine_standardized'].mean()))\n",
    "print('Mean of 2000-2012 over '+str(len(df_2000_2012))+' movies : '+ str(df_2000_2012['feminine_standardized'].mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Number_of_words==max(df.Number_of_words)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34411591",
   "metadata": {},
   "source": [
    "### Is principal character a men or a women?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2287c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('df_movie_usa.csv')\n",
    "df2=pd.read_csv('df_character_usa.csv')\n",
    "sex=[]\n",
    "for ctr,movie_id in enumerate(df1['Freebase_movie_ID']):\n",
    "    #All characters of the movie\n",
    "    characters_serie=df2[df2.Freebase_movie_ID== movie_id]['Character_name']\n",
    "    characters=df2[df2.Freebase_movie_ID== movie_id ]['Character_name'].values\n",
    "    characters=[str(word) for word in characters] #convert all words to a string\n",
    "\n",
    "    #Principal character of the movie (from the summary)\n",
    "    principal_character=df1[df1.Freebase_movie_ID== movie_id]['Principal_summary_character'].values[0]\n",
    "    principal_character=str(principal_character)\n",
    "\n",
    "    if principal_character== 'nan':\n",
    "        sex.append(float('nan'))\n",
    "    \n",
    "    else:\n",
    "        for ctr,char in enumerate(characters):\n",
    "            if principal_character.lower() in char.lower():\n",
    "                index_character= characters_serie[characters_serie==char].index[0]\n",
    "        sex.append( df2.iloc[index_character]['Actor_gender'] )\n",
    "\n",
    "df1['Principal_character_sex']=sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fec0332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_date</th>\n",
       "      <th>Movie_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "      <th>feminine</th>\n",
       "      <th>...</th>\n",
       "      <th>beauty</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>positive_emotion</th>\n",
       "      <th>negative_emotion</th>\n",
       "      <th>Number_of_words</th>\n",
       "      <th>he_count</th>\n",
       "      <th>she_count</th>\n",
       "      <th>Principal_summary_character</th>\n",
       "      <th>Secondary_summary_character</th>\n",
       "      <th>Principal_character_sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Thriller', 'Science Fiction', 'Horror', 'Adv...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ballard</td>\n",
       "      <td>Williams</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Mystery', 'Biographical film', 'Drama', 'Cri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13696889</td>\n",
       "      <td>/m/03cfc81</td>\n",
       "      <td>The Gangsters</td>\n",
       "      <td>1913-05-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>{\"/m/06ppq\": \"Silent film\", \"/m/02h40lc\": \"Eng...</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Short Film', 'Silent film', 'Indie', 'Black-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10408933</td>\n",
       "      <td>/m/02qc0j7</td>\n",
       "      <td>Alexander's Ragtime Band</td>\n",
       "      <td>1938-08-16</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Musical', 'Comedy', 'Black-and-white']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175026</td>\n",
       "      <td>/m/017n1p</td>\n",
       "      <td>Sarah and Son</td>\n",
       "      <td>1930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Drama', 'Black-and-white']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34403</th>\n",
       "      <td>1918494</td>\n",
       "      <td>/m/0660qx</td>\n",
       "      <td>State and Main</td>\n",
       "      <td>2000-08-26</td>\n",
       "      <td>6944471.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/02bjrlw\": \"Italian Language\", \"/m/02h40lc...</td>\n",
       "      <td>['France', 'United States of America']</td>\n",
       "      <td>['Parody', 'Americana', 'Comedy']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Carla</td>\n",
       "      <td>Walt</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34404</th>\n",
       "      <td>664006</td>\n",
       "      <td>/m/030xw6</td>\n",
       "      <td>Guilty as Sin</td>\n",
       "      <td>1993-06-04</td>\n",
       "      <td>22886222.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Thriller', 'Erotic thriller', 'Psychological...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Greenhill</td>\n",
       "      <td>Haines</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34405</th>\n",
       "      <td>24209227</td>\n",
       "      <td>/m/07k5mlk</td>\n",
       "      <td>The Time, the Place and the Girl</td>\n",
       "      <td>1946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Comedy film', 'Romance Film', 'Musical']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34406</th>\n",
       "      <td>35228177</td>\n",
       "      <td>/m/0j7hxnt</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>2011-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34407</th>\n",
       "      <td>9971909</td>\n",
       "      <td>/m/02pygw1</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>1972-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Satire', 'Comedy']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34408 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia_movie_ID Freebase_movie_ID  \\\n",
       "0                  975900         /m/03vyhn   \n",
       "1                 3196793         /m/08yl5d   \n",
       "2                13696889        /m/03cfc81   \n",
       "3                10408933        /m/02qc0j7   \n",
       "4                  175026         /m/017n1p   \n",
       "...                   ...               ...   \n",
       "34403             1918494         /m/0660qx   \n",
       "34404              664006         /m/030xw6   \n",
       "34405            24209227        /m/07k5mlk   \n",
       "34406            35228177        /m/0j7hxnt   \n",
       "34407             9971909        /m/02pygw1   \n",
       "\n",
       "                                              Movie_name  Movie_date  \\\n",
       "0                                         Ghosts of Mars  2001-08-24   \n",
       "1      Getting Away with Murder: The JonBenét Ramsey ...  2000-02-16   \n",
       "2                                          The Gangsters  1913-05-29   \n",
       "3                               Alexander's Ragtime Band  1938-08-16   \n",
       "4                                          Sarah and Son        1930   \n",
       "...                                                  ...         ...   \n",
       "34403                                     State and Main  2000-08-26   \n",
       "34404                                      Guilty as Sin  1993-06-04   \n",
       "34405                   The Time, the Place and the Girl        1946   \n",
       "34406                           Mermaids: The Body Found  2011-03-19   \n",
       "34407                                  Another Nice Mess  1972-09-22   \n",
       "\n",
       "       Movie_revenue  Movie_runtime  \\\n",
       "0         14010832.0           98.0   \n",
       "1                NaN           95.0   \n",
       "2                NaN           35.0   \n",
       "3          3600000.0          106.0   \n",
       "4                NaN           86.0   \n",
       "...              ...            ...   \n",
       "34403      6944471.0          106.0   \n",
       "34404     22886222.0          107.0   \n",
       "34405            NaN          105.0   \n",
       "34406            NaN          120.0   \n",
       "34407            NaN           66.0   \n",
       "\n",
       "                                         Movie_languages  \\\n",
       "0                     {\"/m/02h40lc\": \"English Language\"}   \n",
       "1                     {\"/m/02h40lc\": \"English Language\"}   \n",
       "2      {\"/m/06ppq\": \"Silent film\", \"/m/02h40lc\": \"Eng...   \n",
       "3                     {\"/m/02h40lc\": \"English Language\"}   \n",
       "4                     {\"/m/02h40lc\": \"English Language\"}   \n",
       "...                                                  ...   \n",
       "34403  {\"/m/02bjrlw\": \"Italian Language\", \"/m/02h40lc...   \n",
       "34404                                                 {}   \n",
       "34405                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "34406                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "34407                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "                              Movie_countries  \\\n",
       "0                ['United States of America']   \n",
       "1                ['United States of America']   \n",
       "2                ['United States of America']   \n",
       "3                ['United States of America']   \n",
       "4                ['United States of America']   \n",
       "...                                       ...   \n",
       "34403  ['France', 'United States of America']   \n",
       "34404            ['United States of America']   \n",
       "34405            ['United States of America']   \n",
       "34406            ['United States of America']   \n",
       "34407            ['United States of America']   \n",
       "\n",
       "                                            Movie_genres  feminine  ...  \\\n",
       "0      ['Thriller', 'Science Fiction', 'Horror', 'Adv...       1.0  ...   \n",
       "1      ['Mystery', 'Biographical film', 'Drama', 'Cri...       NaN  ...   \n",
       "2      ['Short Film', 'Silent film', 'Indie', 'Black-...       NaN  ...   \n",
       "3               ['Musical', 'Comedy', 'Black-and-white']       NaN  ...   \n",
       "4                           ['Drama', 'Black-and-white']       NaN  ...   \n",
       "...                                                  ...       ...  ...   \n",
       "34403                  ['Parody', 'Americana', 'Comedy']       1.0  ...   \n",
       "34404  ['Thriller', 'Erotic thriller', 'Psychological...       1.0  ...   \n",
       "34405         ['Comedy film', 'Romance Film', 'Musical']       NaN  ...   \n",
       "34406                                          ['Drama']       0.0  ...   \n",
       "34407                               ['Satire', 'Comedy']       NaN  ...   \n",
       "\n",
       "       beauty  beautiful  positive_emotion  negative_emotion  Number_of_words  \\\n",
       "0         0.0        0.0               0.0               7.0            396.0   \n",
       "1         NaN        NaN               NaN               NaN              NaN   \n",
       "2         NaN        NaN               NaN               NaN              NaN   \n",
       "3         NaN        NaN               NaN               NaN              NaN   \n",
       "4         NaN        NaN               NaN               NaN              NaN   \n",
       "...       ...        ...               ...               ...              ...   \n",
       "34403     0.0        0.0               2.0               1.0            252.0   \n",
       "34404     0.0        0.0               1.0               9.0            611.0   \n",
       "34405     NaN        NaN               NaN               NaN              NaN   \n",
       "34406     0.0        0.0               1.0               0.0            118.0   \n",
       "34407     NaN        NaN               NaN               NaN              NaN   \n",
       "\n",
       "       he_count  she_count  Principal_summary_character  \\\n",
       "0           1.0        0.0                      Ballard   \n",
       "1           NaN        NaN                          NaN   \n",
       "2           NaN        NaN                          NaN   \n",
       "3           NaN        NaN                          NaN   \n",
       "4           NaN        NaN                          NaN   \n",
       "...         ...        ...                          ...   \n",
       "34403       1.0        1.0                        Carla   \n",
       "34404       6.0        8.0                    Greenhill   \n",
       "34405       NaN        NaN                          NaN   \n",
       "34406       0.0        0.0                          NaN   \n",
       "34407       NaN        NaN                          NaN   \n",
       "\n",
       "       Secondary_summary_character Principal_character_sex  \n",
       "0                         Williams                       F  \n",
       "1                              NaN                     NaN  \n",
       "2                              NaN                     NaN  \n",
       "3                              NaN                     NaN  \n",
       "4                              NaN                     NaN  \n",
       "...                            ...                     ...  \n",
       "34403                         Walt                       F  \n",
       "34404                       Haines                       M  \n",
       "34405                          NaN                     NaN  \n",
       "34406                          NaN                     NaN  \n",
       "34407                          NaN                     NaN  \n",
       "\n",
       "[34408 rows x 22 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
